{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from skimage.transform import resize\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color\n",
    "from skimage.io import imread_collection\n",
    "from ast import Yield\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import save_model\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height= 160\n",
    "width=400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de tal manera que cada imagen la dividimos en 6 partes iguales para obtener al final imágenes que contengan un solo dígito en vez del captcha entero. También dividimos las etiquetas de cada captcha para obtener las etiquetas de las nuevas imágenes que contienen solo un dígito cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train/*.png'\n",
    "val_path = 'data/validation/*.png'\n",
    "y_path = 'data/train.csv'\n",
    "y_val_path ='data/validation.csv'\n",
    "Y_train = pd.read_csv(y_path, dtype=str)\n",
    "Y_val = pd.read_csv(y_val_path, dtype=str)\n",
    "train = imread_collection(train_path)\n",
    "val = imread_collection(val_path)\n",
    "Y_train_digits= []\n",
    "Y_val_digits = []\n",
    "Y_train['Label'] = Y_train['Label'].astype(str)\n",
    "Y_val['Label'] = Y_val['Label'].astype(str)\n",
    "list_id = Y_val['Id'].tolist()\n",
    "\n",
    "\n",
    "c =0\n",
    "window = 66\n",
    "X_train=[]\n",
    "X_val=[]\n",
    "X_val_digits=[]\n",
    "for image in train:\n",
    "\n",
    "    for x in range (1,7):\n",
    "        roi = image[0:height, window*(x-1):window*x]\n",
    "        grayscale_image = color.rgb2gray(roi)\n",
    "        flattened_image = grayscale_image.ravel()\n",
    "        normalized_image = (flattened_image - flattened_image.min()) / (flattened_image.max() - flattened_image.min())\n",
    "        Y_train_digits.append(Y_train['Label'].iloc[c][x-1])\n",
    "        X_train.append(normalized_image)\n",
    "        \n",
    "    c+=1\n",
    "c =0\n",
    "\n",
    "for image in val:\n",
    "    X_val.append(image)\n",
    "    \n",
    "    for x in range (1,7):\n",
    "        roi = image[0:height, window*(x-1):window*x]\n",
    "        grayscale_image = color.rgb2gray(roi)\n",
    "        flattened_image = grayscale_image.ravel()\n",
    "        normalized_image = (flattened_image - flattened_image.min()) / (flattened_image.max() - flattened_image.min())\n",
    "        Y_val_digits.append(Y_val['Label'].iloc[c][x-1])\n",
    "        X_val_digits.append(normalized_image)\n",
    "        \n",
    "    c+=1\n",
    "    \n",
    "X_train = np.array(X_train).reshape(-1, height, window, 1)\n",
    "X_val_digits =np.array(X_val_digits).reshape(-1, height, window, 1)\n",
    "Y_train_digits = pd.DataFrame(Y_train_digits, columns=['Label'])\n",
    "Y_val_digits = pd.DataFrame(Y_val_digits, columns=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_images_train = []\n",
    "\n",
    "for image in X_train:\n",
    "    resized_image = resize(image, (80, 66, 1), anti_aliasing=True)\n",
    "    resized_images_train.append(resized_image)\n",
    "\n",
    "resized_images_train = np.array(resized_images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_images_val = []\n",
    "\n",
    "for image in X_val_digits:\n",
    "    resized_image = resize(image, (80, 66, 1), anti_aliasing=True)\n",
    "    resized_images_val.append(resized_image)\n",
    "\n",
    "resized_images_val = np.array(resized_images_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observan los resultados del procesamiento de los datos tanto para los datos  de entrenamiento y de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(36):\n",
    "    plt.subplot(6,6,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i])\n",
    "    label = Y_train_digits.iloc[i]['Label']\n",
    "    plt.title(f'Label is {label}')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(36):\n",
    "    plt.subplot(6,6,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_val_digits[i])\n",
    "    label = Y_val_digits.iloc[i]['Label']\n",
    "    plt.title(f'Label is {label}')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un diccionario para pasar las letras a número y otro diccionario para deshacer el cambio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'a': 10, 'e': 11, 'u': 12}\n",
    "reversed_mapping={v: k for k, v in mapping.items()}\n",
    "Y_train_digits['Label'] = Y_train_digits['Label'].map(lambda x: mapping[x] if x in mapping else x)\n",
    "Y_val_digits['Label'] = Y_val_digits['Label'].map(lambda x: mapping[x] if x in mapping else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos a representar las etiquetas dígitos del 0 al 10 más las letras a, u y e en forma de vectores binarios para adaptarlas al proceso de entrenamiento de nuestra red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "Y_train_one_hot = to_categorical(Y_train_digits)\n",
    "Y_val_one_hot = to_categorical(Y_val_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train_one_hot.shape)\n",
    "print(Y_val_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de la red neuronal convolucional (CNN) a través de Keras:\n",
    "\n",
    "La red consiste de 4 capas Conv2D + MaxPool2D con 64, 128, 256 y 512 filtros respectivamente seguidas por 2 capas fully connected antes de la capa de output con 13 neuronas para las 13 clases posibles. También añadimos una capa de dropout y batch normalization para introducir regularización y evitar el overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten,MaxPooling2D,Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(80, 66, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(13, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(resized_images_train, Y_train_one_hot, validation_data=(resized_images_val, Y_val_one_hot), epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_submission.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('model_subimission.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"test\\*.png\"\n",
    "test = imread_collection(test_path)\n",
    "\n",
    "test_digits=[]\n",
    "c=0\n",
    "for image in test:\n",
    "\n",
    "    for x in range (1,7):\n",
    "        roi = image[0:height, window*(x-1):window*x]\n",
    "        grayscale_image = color.rgb2gray(roi)\n",
    "        flattened_image = grayscale_image.ravel()\n",
    "        normalized_image = (flattened_image - flattened_image.min()) / (flattened_image.max() - flattened_image.min())\n",
    "        test_digits.append(normalized_image)\n",
    "        \n",
    "    c+=1\n",
    "\n",
    "test_digits = np.array(test_digits).reshape(-1, height, window, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_images_test = []\n",
    "\n",
    "for image in test_digits:\n",
    "    resized_image = resize(image, (80, 66, 1), anti_aliasing=True)\n",
    "    resized_images_test.append(resized_image)\n",
    "\n",
    "resized_images_test = np.array(resized_images_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar el output de los datos de validación iteramos por todos los ejemplos en el array de dígitos extraidos de los datos de validación. Como cada captcha se compone de 6 dígitos en total, cada 6 dígitos que predice nuestro modelo los concatenan y llena una entrada en el fichero de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aa=0\n",
    "output=[]\n",
    "captcha=[]\n",
    "id=0\n",
    "for example in resized_images_test:\n",
    "\n",
    "    pred = np.argmax(model.predict(example.reshape(1, 80, window, 1)))\n",
    "    \n",
    "    captcha.append(reversed_mapping[pred] if pred in reversed_mapping else pred)\n",
    "    \n",
    "    if aa == 5:\n",
    "        joined = ''.join(map(str, captcha))\n",
    "        output.append([id,joined])\n",
    "        captcha = []\n",
    "        aa = 0\n",
    "        id+=1\n",
    "    else:\n",
    "        aa += 1\n",
    "\n",
    "csv_file_path = \"output2.csv\"\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Id', 'Label'])\n",
    "    writer.writerows(output)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
